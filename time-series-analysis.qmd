---
title: "Time Series Analysis of Spotify Data"
author: Frankie, Anna, Piper, Kate, Ayaan
format: 
  html:
    self-contained: true
---

```{r setup, echo=FALSE, message=FALSE, include = FALSE}
# load packages
library(tidyverse)
library(knitr)
library(broom)
library(gridExtra)
library(cowplot)
library(xts)
library(forecast)
library(yardstick)
library(lubridate)
library(fable)
library(patchwork)
library(gt)
```

```{r load-data, message=FALSE, include = FALSE}
# load data
spotify_data = read_csv("data/spotify_data.csv")
theme_set(theme_minimal())
```

## Introduction

Companies are always looking for methods to analyze the popularity of their products, as well as what predicts that popularity over time. The music industry is no different: Spotify has developed a popularity index that ranks songs from 0 to 100 on how popular they are compared to other songs. The score has three components: total streams of a song, how recently a song has been played, and the frequency at which a song is played. This score is immensely useful to Spotify and to music industry professionals on a song-by-song basis, because having a high popularity score increases a song's discoverability to listeners. However, modeling mean values of song popularity over time also has the potential to be useful for Spotify (or similar streaming platforms), because it could help companies understand the factors that play into users' satisfaction with the platform and listening patterns over time, as well as predict future values of popularity that might inform business decisions. We have obtained a Kaggle dataset containing information about audio features of more than 160,000 Spotify songs that were released between 1921 and 2020. While several previous analyses have looked at this data and even examined the relationships between features and popularity, these projects have ignored the implicit potential for temporal autocorrelation in the data. Because the total number of listens for a given song inevitably increases over time, and because frequency and recency of listens depend in large part on media attention and artist activity, the mean song popularity for songs released in one month is likely to be highly related to that of songs released the previous month. Our goal for this project is to create a model of the mean popularity for songs released at given intervals over time using song feature data as predictors and ARIMA errors to account for leftover temporal autocorrelation. 

## Data Preparation and Exploratory Data Analysis

The original dataset for this project contains nineteen variables, including song name, artist, name, release date, and audio features including acousticness, danceability, loudness and energy. A full codebook of all variables and their definitions is located in the data folder of this repository (`spotify_data_codebook.md`). The original data contained audio features and identification information for 169,909 songs. 

### Data Preparation

First, we altered the structure of our data, creating a new dataset (`spotify_mean_yearly`) that contains each year from 1921 to 2010 and the mean values of the following feature variables: acousticness, danceability, duration, energy, explicit, instrumentalness, key, liveness, loudness, mode, popularity, speechiness, tempo, and valence. We also created a dataset at monthly granularity to establish a regular time interval off which to model. Notably, filtering the release date for only observations that contain monthly data meant we disincluded about 30% of observations (50382 out of 169909 originally), but we don't have a strong reason to believe that this aggregation will produce bias in the data, given that the time series for yearly mean popularity of songs with and without monthly data matched (see plot).  

```{r clean data, message = FALSE, echo = FALSE, out.width = "60%", out.width = "60%"}
# data cleaning
cols_to_drop <- c("year", "release_date", "id", "name", "artists")
all_cols <- colnames(spotify_data)
stat_cols<- all_cols[all_cols %in% cols_to_drop == FALSE]

#create yearly granularity dataset 
spotify_mean_yearly <- spotify_data %>% 
  group_by(year) %>% 
  summarise_at(stat_cols, list(year_mean = mean)) %>% 
  filter(year < 2020)

#create monthly granularity dataset 
spotify_mean_monthly <- spotify_data %>% 
  filter(nchar(release_date) > 7) %>%
  group_by(month = lubridate::floor_date(as.Date(release_date), 'month')) %>% 
  summarise_at(stat_cols, list(month_mean = mean)) %>% 
  filter(month < '2020-01-01')

#check that aggregation won't bias
spotify_data %>%
  mutate(hasmonth = ifelse(nchar(release_date) < 7, "no", "yes")) %>%
  group_by(year, hasmonth) %>%
  summarize(count = n(), meanpop = mean(popularity)) %>% 
  group_by(year) %>%
  mutate(perc = count/sum(count))%>%
  ggplot(aes(x = year, y = meanpop, color = hasmonth)) + 
  geom_line(linewidth = 1) + 
  labs(title = "Yearly time series of Spotify data by available granularity",
       color = "Has month?",
       x = "Year",
       y = "Mean popularity score") + theme_minimal() + 
  scale_color_manual(values = c("#191414", "#1DB954"))
```

### EDA: Trends over time

In order to get a general sense of the trends in this data, we plotted the mean yearly values of each of the song feature variables.  

```{r visualize yearly data, message = FALSE, echo = FALSE}
# data visualization for yearly trends
pop_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, y = popularity_year_mean)) +
  geom_line(color = "#1DB954") + 
  theme_minimal() + 
  labs(
    x = "Year",
    y = "Song Popularity Mean",
    title = "Yearly ts Popularity"
  )

loud_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, y = loudness_year_mean)) +
  geom_line(color = "#1DB954") + 
  theme_minimal() + 
  labs(
    x = "Year",
    y = "Song Loudness Mean",
    title = "Yearly ts Loudness")  

acoustic_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, y = acousticness_year_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Acousticness Mean",
    title = "Yearly ts Acoustic"
  )

energy_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, y = energy_year_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Energy Mean",
    title = "Yearly ts Energy"
  )

danceability_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, danceability_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Danceability Mean",
    title = "Yearly ts Danceability"
  )

liveness_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, liveness_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Liveness Mean",
    title = "Yearly ts Liveness"
  )

duration_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, duration_ms_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Duration Mean",
    title = "Yearly ts Duration"
  )

instrumentalness_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, instrumentalness_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Instrumentalness Mean",
    title = "Yearly ts Instrumentalness"
  )

explicitness_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, explicit_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Explicitness Mean",
    title = "Yearly ts Explicitness"
  )

speechiness_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, speechiness_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Speechiness Mean",
    title = "Yearly ts Speechiness"
  )

tempo_line_plot <- ggplot(data = spotify_mean_yearly, aes(x = year, tempo_year_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
   labs(
    x = "Year",
    y = "Song Tempo Mean",
    title = "Yearly ts Tempo"
  )
grid.arrange(pop_line_plot, loud_line_plot, acoustic_line_plot, 
             energy_line_plot, liveness_line_plot, danceability_line_plot, nrow = 2)

grid.arrange(duration_line_plot, instrumentalness_line_plot, explicitness_line_plot, 
             speechiness_line_plot, tempo_line_plot, NULL, nrow = 2)
```
Of note, mean song popularity increased steeply over time. This probably has to do with the rise of the internet and free music streaming, which happened during the last couple of decades. However, mean song popularity decreased sharply in the last couple of years-- perhaps because not as many people have had the chance to listen to certain songs yet. Mean loudness and energy have generally increased over time, while mean song acousticness has dropped. Mean song liveness and instrumetalness had moderate downward trends. Mean song duration rose over time but has dropped again in the last couple of decades. Song danceability fell from the 1920s to the 1950s but has been on an upward trajectory ever since.

Now, we plotted the plot the mean monthly values of each of the song feature variables to examine these trends at a more granular level.

```{r monthly data, message = FALSE, echo = FALSE}
# data visualization for monthly
pop_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, y = popularity_month_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Popularity Mean",
    title = "Monthly Popularity"
  )

loud_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, y = loudness_month_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Loudness Mean",
    title = "Monthly Loudness"
  )

acoustic_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, y = acousticness_month_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Acousticness Mean",
    title = "Monthly Acoustic"
  )

energy_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, y = energy_month_mean)) +
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Energy Mean",
    title = "Monthly Energy"
  )

danceability_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, danceability_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Danceability Mean",
    title = "Monthly Danceability"
  )

liveness_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, liveness_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Liveness Mean",
    title = "Monthly Liveness"
  )

duration_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, duration_ms_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Duration Mean",
    title = "Monthly Duration"
  )

instrumentalness_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, instrumentalness_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Instrumentalness Mean",
    title = "Monthly Instrumentalness"
  )

explicitness_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, explicit_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Explicitness Mean",
    title = "Montly Explicitness"
  )

speechiness_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, speechiness_month_mean))+
  geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Speechiness Mean",
    title = "Monthly Speechiness"
  )

tempo_line_plotm <- ggplot(data = spotify_mean_monthly, aes(x = month, tempo_month_mean))+
 geom_line(color = "#1DB954") + 
  theme_minimal() + 
     labs(
    x = "Month",
    y = "Song Tempo Mean",
    title = "Monthly Tempo"
  )

grid.arrange(pop_line_plotm, loud_line_plotm, acoustic_line_plotm, 
             energy_line_plotm, liveness_line_plotm, danceability_line_plotm, 
             nrow = 2)

grid.arrange(duration_line_plotm, instrumentalness_line_plotm, explicitness_line_plotm, 
             speechiness_line_plotm, tempo_line_plotm, NULL, 
             nrow = 2)
```

After plotting at a monthly timescale, we can see more nuance in these trends. For instance, the downward trend in liveness that we observed in the yearly time series for liveness appears to be at least partially a result of a couple of months early in the century with particularly high mean liveness that biased the averages. Similarly, for instrumentalness, there seemed to be much more variance in mean monthly values early in the century that created the illusion of a crisper downward trend. Because these monthly time series apear to give us far more information than yearly time series, at this point we chose to create a model that explains monthly mean popularity based on monthly mean predictor values rather than using a yearly temporal granularity. Additionally, the ability to predict monthly mean popularity would likely be more useful for a company than yearly in terms of making timely and specific business decisions. 

### Bivariate EDA: Relationships between popularity and song features 

To continue our EDA and check which of these covariates might have a relationship with our outocme variable, song popularity, we plotted each variable against the response at monthly granularity. We also fit a rudimentary linear model (black) and loess curve (green) to each. 

```{r bv plots, message = FALSE, echo = FALSE}
#need to add titles & fix axes 
dance_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=danceability_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.25, se = FALSE) +
  labs(title = "Dance on popularity", y = "Mean popularity", x = "Mean dance score")

loud_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=loudness_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Loudness on popularity", y = "Mean popularity", x = "Mean loudness score")

energy_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=energy_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Energy on popularity", y = "Mean popularity", x = "Mean energy score")

instrumentalness_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=instrumentalness_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Instrumentalness", y = "Mean popularity", x = "Mean instrumentalness")

acousticness_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=acousticness_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Acousticness on popularity", y = "Mean popularity", x = "Mean acousticness score")

liveness_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=liveness_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Liveness on popularity", y = "Mean popularity", x = "Mean liveness score")

duration_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=duration_ms_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Duration on popularity", y = "Mean popularity", x = "Mean duration")

explicitness_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=explicit_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Explicitness on popularity", y = "Mean popularity", x = "Mean explicitness")

speechiness_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=speechiness_month_mean, y = popularity_month_mean)) + 
 geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
    geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Speechiness on popularity", y = "Mean popularity", x = "Mean speechiness")

tempo_bveda <- spotify_mean_monthly %>%
  ggplot(aes(x=tempo_month_mean, y = popularity_month_mean)) + 
  geom_point(color = "#B7B6C2") + 
  theme_minimal() + 
  geom_smooth(color='#191414', alpha = 0.75,se = FALSE, method = "lm") + 
  geom_smooth(color = "#1DB954", alpha = 0.75, se = FALSE) +
  labs(title = "Tempo on popularity", y = "Mean popularity", x = "Mean tempo score")

grid.arrange(dance_bveda, loud_bveda, energy_bveda, 
             instrumentalness_bveda, acousticness_bveda, liveness_bveda, 
             nrow = 2)

grid.arrange(speechiness_bveda, duration_bveda, tempo_bveda, 
             explicitness_bveda, NULL, NULL, nrow = 2)
```

The bivariate EDA (grouped rowwise by behavior), revealed some trends between the predictor and mean monthly song popularity. Danceability, Loudness, and Energy all had relatively strong positive trends with mean song popularity. Instrumentalness, Acousticness, and Liveness all had negative trends with song popularity (higher values of the predictor giving lower song popularity, and vice versa). Speechiness, Duration, and Tempo all had values gathered in one area with various popularity levels, and explicitness had a moderate positve trend with mean song popularity. The loess curve reveals some strange behavior at the very high or very low values of all eight, likely due to the fact that these more extreme popularity values are uncommon.  

### Checking cross correlation 

For the final step of our EDA, we checked the cross correlation function and correlation coefficients at lags 0-11 for all predictors. For most of the variables, the highest pacf spike was at 0, and calculating the correlations at each lag confirmed that adding a lag would likely not improve the model. Only the tempo variable showed a higher correlation with the addition of lag (lag by 10 months). 

```{r, echo=FALSE, results='hide'}
#lag correlations of energy on popularity 
spotify_mean_monthly %>%
  filter(popularity_month_mean > 0) %>%
  select(month, energy_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(energy_month_mean,0),
    "lag 1" = lag(energy_month_mean,1),
    "lag 2" = lag(energy_month_mean,2),
    "lag 3" = lag(energy_month_mean,3),
    "lag 4" = lag(energy_month_mean,4),
    "lag 5" = lag(energy_month_mean,5),
    "lag 6" = lag(energy_month_mean,6),
    "lag 7" = lag(energy_month_mean,7),
    "lag 8" = lag(energy_month_mean,8),
    "lag 9" = lag(energy_month_mean,9),
    "lag 10" = lag(energy_month_mean,10),
    "lag 11" = lag(energy_month_mean,11))%>%
  select(-energy_month_mean, -month) %>%
  tidyr::gather(lag, energy_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(energy_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of danceability on popularity 
spotify_mean_monthly %>%
  select(month, danceability_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(danceability_month_mean,0),
    "lag 1" = lag(danceability_month_mean,1),
    "lag 2" = lag(danceability_month_mean,2),
    "lag 3" = lag(danceability_month_mean,3),
    "lag 4" = lag(danceability_month_mean,4),
    "lag 5" = lag(danceability_month_mean,5),
    "lag 6" = lag(danceability_month_mean,6),
    "lag 7" = lag(danceability_month_mean,7),
    "lag 8" = lag(danceability_month_mean,8),
    "lag 9" = lag(danceability_month_mean,9),
    "lag 11" = lag(danceability_month_mean,11),
    "lag 10" = lag(danceability_month_mean,10))  %>%
  select(-danceability_month_mean, -month) %>%
  tidyr::gather(lag, danceability_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(danceability_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of loudness on popularity 
spotify_mean_monthly %>%
  select(month, loudness_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(loudness_month_mean,0),
    "lag 1" = lag(loudness_month_mean,1),
    "lag 2" = lag(loudness_month_mean,2),
    "lag 3" = lag(loudness_month_mean,3),
    "lag 4" = lag(loudness_month_mean,4),
    "lag 5" = lag(loudness_month_mean,5),
    "lag 6" = lag(loudness_month_mean,6),
    "lag 7" = lag(loudness_month_mean,7),
    "lag 8" = lag(loudness_month_mean,8),
    "lag 9" = lag(loudness_month_mean,9),
    "lag 11"= lag(loudness_month_mean,11),
    "lag 10"= lag(loudness_month_mean,10))  %>%
  select(-loudness_month_mean, -month) %>%
  tidyr::gather(lag, loudness_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(loudness_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of acousticness on popularity 
spotify_mean_monthly %>%
  select(month, acousticness_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(acousticness_month_mean,0),
    "lag 1" = lag(acousticness_month_mean,1),
    "lag 2" = lag(acousticness_month_mean,2),
    "lag 3" = lag(acousticness_month_mean,3),
    "lag 4" = lag(acousticness_month_mean,4),
    "lag 5" = lag(acousticness_month_mean,5),
    "lag 6" = lag(acousticness_month_mean,6),
    "lag 7" = lag(acousticness_month_mean,7),
    "lag 8" = lag(acousticness_month_mean,8),
    "lag 9" = lag(acousticness_month_mean,9),
    "lag 11"= lag(acousticness_month_mean,11),
    "lag 10"= lag(acousticness_month_mean,10))  %>%
  select(-acousticness_month_mean, -month) %>%
  tidyr::gather(lag, acousticness_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(acousticness_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of duration on popularity 
spotify_mean_monthly %>%
  select(month, duration_ms_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(duration_ms_month_mean,0),
    "lag 1" = lag(duration_ms_month_mean,1),
    "lag 2" = lag(duration_ms_month_mean,2),
    "lag 3" = lag(duration_ms_month_mean,3),
    "lag 4" = lag(duration_ms_month_mean,4),
    "lag 5" = lag(duration_ms_month_mean,5),
    "lag 6" = lag(duration_ms_month_mean,6),
    "lag 7" = lag(duration_ms_month_mean,7),
    "lag 8" = lag(duration_ms_month_mean,8),
    "lag 9" = lag(duration_ms_month_mean,9),
    "lag 11"= lag(duration_ms_month_mean,11),
    "lag 10"= lag(duration_ms_month_mean,10))  %>%
  select(-duration_ms_month_mean, -month) %>%
  tidyr::gather(lag, duration_ms_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(duration_ms_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of liveness on popularity 
spotify_mean_monthly %>%
  select(month, liveness_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(liveness_month_mean,0),
    "lag 1" = lag(liveness_month_mean,1),
    "lag 2" = lag(liveness_month_mean,2),
    "lag 3" = lag(liveness_month_mean,3),
    "lag 4" = lag(liveness_month_mean,4),
    "lag 5" = lag(liveness_month_mean,5),
    "lag 6" = lag(liveness_month_mean,6),
    "lag 7" = lag(liveness_month_mean,7),
    "lag 8" = lag(liveness_month_mean,8),
    "lag 9" = lag(liveness_month_mean,9),
    "lag 11"= lag(liveness_month_mean,11),
    "lag 10"= lag(liveness_month_mean,10))  %>%
  select(-liveness_month_mean, -month) %>%
  tidyr::gather(lag, liveness_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(liveness_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of instrumentalness on popularity 
spotify_mean_monthly %>%
  select(month, instrumentalness_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(instrumentalness_month_mean,0),
    "lag 1" = lag(instrumentalness_month_mean,1),
    "lag 2" = lag(instrumentalness_month_mean,2),
    "lag 3" = lag(instrumentalness_month_mean,3),
    "lag 4" = lag(instrumentalness_month_mean,4),
    "lag 5" = lag(instrumentalness_month_mean,5),
    "lag 6" = lag(instrumentalness_month_mean,6),
    "lag 7" = lag(instrumentalness_month_mean,7),
    "lag 8" = lag(instrumentalness_month_mean,8),
    "lag 9" = lag(instrumentalness_month_mean,9),
    "lag 11"= lag(instrumentalness_month_mean,11),
    "lag 10"= lag(instrumentalness_month_mean,10))  %>%
  select(-instrumentalness_month_mean, -month) %>%
  tidyr::gather(lag, instrumentalness_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(instrumentalness_month_mean, popularity_month_mean, use="complete.obs"))

#lag correlations of speechiness on popularity 
spotify_mean_monthly %>%
  select(month, speechiness_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(speechiness_month_mean,0),
    "lag 1" = lag(speechiness_month_mean,1),
    "lag 2" = lag(speechiness_month_mean,2),
    "lag 3" = lag(speechiness_month_mean,3),
    "lag 4" = lag(speechiness_month_mean,4),
    "lag 5" = lag(speechiness_month_mean,5),
    "lag 6" = lag(speechiness_month_mean,6),
    "lag 7" = lag(speechiness_month_mean,7),
    "lag 8" = lag(speechiness_month_mean,8),
    "lag 9" = lag(speechiness_month_mean,9),
    "lag 11"= lag(speechiness_month_mean,11),
    "lag 10"= lag(speechiness_month_mean,10))  %>%
  select(-speechiness_month_mean, -month) %>%
  tidyr::gather(lag, speechiness_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(corr = cor(speechiness_month_mean, popularity_month_mean, use="complete.obs"))
```

```{r echo = FALSE, warning=FALSE}
#lag correlations of tempo on popularity 
spotify_mean_monthly %>%
  select(month, tempo_month_mean, popularity_month_mean) %>%
  mutate(
    "lag 0" = lag(tempo_month_mean,0),
    "lag 1" = lag(tempo_month_mean,1),
    "lag 2" = lag(tempo_month_mean,2),
    "lag 3" = lag(tempo_month_mean,3),
    "lag 4" = lag(tempo_month_mean,4),
    "lag 5" = lag(tempo_month_mean,5),
    "lag 6" = lag(tempo_month_mean,6),
    "lag 7" = lag(tempo_month_mean,7),
    "lag 8" = lag(tempo_month_mean,8),
    "lag 9" = lag(tempo_month_mean,9),
    "lag 11"= lag(tempo_month_mean,11),
    "lag 10"= lag(tempo_month_mean,10))  %>%
  select(-tempo_month_mean, -month) %>%
  tidyr::gather(lag, tempo_month_mean, -popularity_month_mean) %>%
  group_by(lag) %>%
  summarize(Correlation = cor(tempo_month_mean, popularity_month_mean, use="complete.obs"))%>%
  arrange(nchar(lag)) %>%
  gt() %>% tab_options(column_labels.background.color = "#1DB954")

#plot lag CCF
forecast::ggCcf(spotify_mean_monthly$tempo_month_mean, 
                spotify_mean_monthly$popularity_month_mean,
                main = "Checking Lag for Tempo")

```

### Fitting preliminary ARIMA model to Popularity scores

As part of our EDA, we used a step-by-step process to create an ARIMA model of mean popularity scores over time by year from 1921 to 2020. Ultimately, we will attempt to use an ARIMA component to account for left over temporal autocorrelation of the residuals in our linear model of mean song popularity based on mean song features for a given year; this initial ARIMA model may help us to inform that component by showing us the temporal patterns in song popularity over time. 

```{r step1}
# covert dataframe to time series
spotify_ts <- xts(spotify_mean_monthly$popularity_month_mean, spotify_mean_monthly$month)
spotify_ts <- as.ts(spotify_ts)

# forecast ARIMA
step1 <- forecast::ggtsdisplay(spotify_ts, points = FALSE, theme = theme_minimal())
```

Based on the time series visualization, we will begin by applying
first-order differencing with an $ARIMA(0,1,0)$ model. We will also 
store the root mean squared error value to track our progress while 
iterating through ARIMA models.

```{r step2, cache=TRUE}
# first-order differencing
step2 <- forecast::Arima(
  spotify_ts, order = c(0, 1, 0)
)
forecast::ggtsdisplay(step2$residuals, points = FALSE, lag.max = 36)

# store rmse value
step2_rmse <- yardstick::rmse_vec(
  spotify_ts %>% unclass(),
  step2$fitted %>% unclass()
)
```

The time series has somewhat improved, but there remains some patterns
that we can alleviate with an AR process. We will apply a MA(2) process
on top of the first-order differencing with an $ARIMA(0,1,2)$ model. 

```{r step3, cache=TRUE}
# first order differencing
# MA(2)
step3 <- forecast::Arima(
  spotify_ts, order = c(0, 1, 2)
)
forecast::ggtsdisplay(step3$residuals, points = FALSE, lag.max = 36)

# store rmse value
step3_rmse <- yardstick::rmse_vec(
  spotify_ts %>% unclass(),
  step3$fitted %>% unclass()
 )
```

The AR component somewhat improved the model, bringing the root mean squared
error from `r round(step2_rmse, 2)` to `r round(step3_rmse, 2)`. We can confirm
our findings using the `auto.arima` function:

```{r auto-model-selection}
# auto arima on time series
forecast::auto.arima(spotify_ts)
```

```{r model-fit, warning = FALSE}
# model fit
model = "Final Model - forecast::Arima (0,1,2) "
rmse = (spotify_ts-step3$fitted)^2 %>% mean() %>% sqrt() %>% round(3) %>% paste0("   [RMSE: ", . ,"]")

step3 %>%
  {tibble(
    spotify_ts = spotify_ts %>% unclass(),
    model = .$fitted %>% unclass(),
    time  = time(.$fitted) %>% unclass()
  )} %>% 
  tidyr::gather(var, popularity_year_mean, -time) %>%
  mutate(var = forcats::as_factor(var)) %>%
  ggplot(aes(x=time, y=popularity_year_mean, color=var)) + 
  geom_line(alpha=0.75, size=0.8) +
  scale_color_manual(values = c("#191414", "#1DB954"), labels = c("Spotify time series", "Model fit"))+
    labs(title = paste(model, rmse), x = "Time", y = "Average Popularity Score",
         color = "")
```

After applying first order differencing and an MA(2) component,
the model fit appears to be finished! The ACF and PACF do not appear to have a pattern 
after the final step, and the final model against the given data looks sufficient as well. 
The model for this data required the following parameters: $ARIMA(0,1,2)$, and the final 
root mean squared error is `r round(step3_rmse, 2)`.

```{r arima-model-output, include = FALSE}
# report ARIMA model
m = as_tsibble(spotify_ts) %>% 
  model(ARIMA(value ~ pdq(0, 1, 2)))
```

## Model fitting 

Our goal in creating this model is to predict monthly mean song popularity based on monthly mean song features. From our EDA, we can see that danceability, energy, explicitness, instrumentalness, loudness, and tempo had plausibly linear associations with monthly mean song popularity. We will start by fitting a multiple linear regression model with mean monthly popularity as the outcome, the features identified in EDA as predictors, and no temporal component. 

```{r}
# fit model
model1 <- lm(popularity_month_mean ~ danceability_month_mean + energy_month_mean + explicit_month_mean +
               instrumentalness_month_mean + loudness_month_mean + tempo_month_mean, data = spotify_mean_monthly) 

# output model
summary(model1)

# store RMSE and AIC
model1_rmse <- yardstick::rmse_vec(
  spotify_mean_monthly$popularity_month_mean,
  model1$fitted
 )
model1_aic <- AIC(model1)
```

```{r, echo=FALSE}
# plot predicted values and actual values
spotify_mean_monthly$predmodel1 = predict(model1)
ggplot(spotify_mean_monthly, aes(y = popularity_month_mean, x = month, color)) +
  geom_line(color = "#191414") + 
  geom_line(aes(y = predmodel1), color = "#1DB954", alpha = 0.8) + 
  labs(title = "Predicted (green) vs. Observed (black), Model 1", 
       x = "Time", y = "Mean popularity")
```

The model performed decently, with an root mean squared error or `r round(model1_rmse, 3)` and an AIC of `r round(model1_aic, 3)`. We want to include some temporal component, so we will move forward by adding a temporal component to our existing model with a cross correlation function lag term on the tempo predictor.

```{r}
# fit model
model2 = lm(popularity_month_mean ~ danceability_month_mean + energy_month_mean + explicit_month_mean + 
              instrumentalness_month_mean + loudness_month_mean + tempo_month_mean + 
              lag(tempo_month_mean, 10),
            data = spotify_mean_monthly)

# output model
summary(model2)

# store RMSE and AIC
model2_rmse <- model2 %>% 
  broom::augment(newdata = spotify_mean_monthly) %>% 
  mutate(rmse = yardstick::rmse_vec(popularity_month_mean, .fitted)) %>% 
  select(rmse) %>% 
  first() %>% 
  pull()

model2_aic <- AIC(model2)
```

The new model performed better, with an root mean squared error or `r round(model2_rmse, 3)` and an AIC of `r round(model2_aic, 3)`. The temporal component improved the model, so we will move forward by visualizing the residuals and considering a cross correlation function lag term on the response.

```{r echo = FALSE}
# visualize residuals
forecast::ggtsdisplay(model2$residuals, points=FALSE)

# visualize lag on residuals
forecast::ggCcf(spotify_mean_monthly$popularity_month_mean, model2$residuals)
```
From the residuals of model 2, we can see that there is likely some unaccounted for temporal autocorrelation. In this plot of the CCF of the response variable vs the residuals, we can see a spike at 10, which suggests the use of a lag(10) on the response variable as one of the predictors. For our third model attempt, we will add this predictor to model 2.

```{r}
# fit model
model3 = lm(popularity_month_mean ~ danceability_month_mean + energy_month_mean + explicit_month_mean + 
              instrumentalness_month_mean + loudness_month_mean + tempo_month_mean + 
              lag(tempo_month_mean, 10) + lag(popularity_month_mean, 10),
            data = spotify_mean_monthly)

# output model
summary(model3)

# store RMSE and AIC
model3_rmse <- model3 %>% 
  broom::augment(newdata = spotify_mean_monthly) %>% 
  mutate(rmse = yardstick::rmse_vec(popularity_month_mean, .fitted)) %>% 
  select(rmse) %>% 
  first() %>% 
  pull()

model3_aic <- AIC(model3)
```

```{r, echo=FALSE}
# plot predicted values and actual values
model3 %>% 
  broom::augment(newdata = spotify_mean_monthly) %>% 
  ggplot(aes(y = popularity_month_mean, x = month)) +
  geom_line(color = "#191414") + 
  geom_line(aes(y = .fitted), color ="#1DB954", alpha = 0.9) + 
  labs(title = "Predicted (green) vs. Observed (black), Model 3",
       x = "Time", y = "Mean popularity")
```

The third model performed even better than the prior two, with an root mean squared error or `r round(model3_rmse, 3)` and an AIC of `r round(model3_aic, 3)`. This technique is one way to account for temporal trends in our model, but now we will try a different technique, the use of standard regression as in model 1 but with ARIMA errors.

The following model uses the same predictors as model 1, but the intercept has been removed and auto ARIMA has been used to fit the errors.

```{r}
# Create matrix of predictors
xreg <- cbind(energy_month_mean=spotify_mean_monthly$energy_month_mean, 
              explicit_month_mean=spotify_mean_monthly$explicit_month_mean,
              danceability_month_mean=spotify_mean_monthly$danceability_month_mean, 
              instrumentalness_month_mean=spotify_mean_monthly$instrumentalness_month_mean,
              loudness_month_mean=spotify_mean_monthly$loudness_month_mean, 
              tempo_month_mean=spotify_mean_monthly$tempo_month_mean
              )

# Remove intercept and isolate response variable
xreg <- xreg[,-1]
popularity <- ts(spotify_mean_monthly$popularity_month_mean)

# fit model
model4 <- auto.arima(popularity, xreg=xreg)

# output model
summary(model4)

# store AIC
model4_aic <- AIC(model4)

# visualize predicted versus actual 
spotify_mean_monthly %>%
  mutate(fitted = model4$fitted) %>% 
  ggplot(aes(y = popularity_month_mean, x = month)) +
  geom_line(color = "#191414") + 
  geom_line(aes(y = fitted), color = "#1DB954") + 
  labs(title = "Predicted (green) vs. Observed (black), Model 4",
       x = "Time", y = "Mean popularity")
```

Interestingly, auto ARIMA produced the same ARIMA model as the ARIMA model we fit to the mean monthly popularity time series in EDA.  This model had the best AIC value of all four models, yielding an AIC of `r round(model4_aic, 3)`. 

## Discussion

In this project, we fit a model to the mean popularity of songs released every month from 1920 to 2020 using multiple linear regression with ARIMA errors. We started by doing univariate exploratory data analysis, at which point we decided to construct our model at a monthly temporal granularity. Then, we did bivariate analysis to investigate the relationship between each potential predictor variable and mean monthly popularity. We used this analysis to select predictor variables for our model. Our initial model was a simple multiple linear regression model with mean popularity as the dependent variable and each of the mean monthly predictor variables as covariates. After plotting the predicted values from this model against the actual data, it was clear that the combination of covariates we had chosen did have value in predicting the mean monthly popularity, as expected based on the relationships we observed during bivariate analysis. However, there was clearly still a lot of noise that was unaccounted for, which we suspected was due to temporal trends in the data. We decided to try two different approaches to accounting for the spatial component of this model. First, we  used cross-correlation functions to check whether lagging any of the predictors would be useful; we ended up lagging one of the variables by 10 month and then based on the residuals of that model we included a 10-month lag on the response variable as one of the predictors. Both of these steps lowered the AIC, which we used as a model comparison metric. For our second approach, we used the same original multiple linear regression model but then fit an ARIMA model to the leftover temporal autocorrelation. Interestingly, using the automatic ARIMA function generated the same ARIMA parameters (0,1,2) as the manually fitted ARIMA model we fitted to the mean monthly popularity time series as part of exploratory data analysis. This model produced the lowest AIC value of all of the models fit up to that point, leading us to believe that a multiple linear regression with ARIMA errors is better suited to this data than using lagged predictors as covariates in a traditional regression model. 

Our final model is a multiple linear regression model with ARIMA errors. The MLR covariates included are mean monthly values of the following song features: energy (a measure of intensity), explicitness, danceability, instrumentalness (amount of vocal content), loudness, and tempo. Higher loudness, danceability and explicitness are associated with higher popularity holding the other predictors constant, while higher instrumentalness and tempo are associated with lower popularity holding all else constant. The ARIMA errors are first-order differenced, with an AR component of 0 and an MA component of 2.

From healthcare data to company analytics, real-world data often includes temporal components. Models of indices like the Spotify popularity index are essential for a company’s ability to predict trends over time and to understand what factors impact customer engagement in relation to time. We have found that a multiple linear regression model with ARIMA errors is best suited to modeling mean monthly song popularity based on song release dates and other features data. Future investigations of temporal trends in Spotify data could include split modeling to gain a better understanding of how predictors have differentially affected popularity depending on the time  period of release date and  dividing up the three facets of the popularity index (listen total, frequency and recency) to see how predictors affect these outcomes differently. A key limitation of this project is that while the acoustic features of songs likely trend towards certain values based on what is popular in society at a given time, they fail to capture elements like artist popularity and media/social media attention that are inherently essential considerations in modeling song popularity. Spotify also has a measure of artist popularity, and future modeling projects using this data should consider linking that metric to this data as a proxy measure for the various components of the public attention directed toward a song that are likely to be extremely predictive of its popularity . 


### Appendix/ Extra Analysis:

As a supplement to our analysis of mean monthly song popularity, we decided to do an analysis of the predictors of individual song popularity, given the potential usefulness of this kind of model for music-industry professionals. We used Python instead of R for this supplementary analysis. After conducting a  more detailed exploratory data  analysis that included more data visualization, outlier detection (detectionof white noise and other non-song tracks) and an investigation of the interaction between time period and each predictor, we fit a simplified regression model using just song metrics, a regression model with interactions that account for the temporally varying nature of the data (song metrics interacted with the decade they are from), and a neural network and compared the three models. 

The notebook and modeling PDF have been linked below, but are not in this report, due to its sheer length.

[Link to popularity modeling notebook here](https://github.com/sta344-fa22/project_fapka/blob/main/Popularity%20Modeling.pdf)

[Link to popularity modeling PDF (code not suppressed due to Co-Lab) here](https://github.com/sta344-fa22/project_fapka/blob/main/Popularity_Modeling.ipynb)

Below is the regression model using just song metrics.

Simple model RMSE score on unseen testing data: 253.76717755170372
Simple model R^2 score on unseen testing data: 0.4594513660578803

Below is a plot of X being the predicted popularity by the model and Y being the true popularity. 


```{r}

knitr::include_graphics('Simple Fit.png')


```

We then created a model using a regression of the 30 most important features found by a recursive feature elimination of interactions between every decade and each song metric. Interactions were used as the relationship a song metric has with popularity appeared to change throughout time, based on the trend of the era, which was demonstrated in the data visualization in the report. Additionally, music itself has become more popular in time, or rather, more recent music will have more streams on Spotify by nature of its constituency. The key interactions found from RFE were 
 'liveness decade_1930s', 'liveness decade_1940s', 'liveness decade_1950s', 'loudness decade_1920s', 'loudness decade_1930s', 'loudness decade_1940s', 'loudness decade_1950s','loudness decade_1960s','loudness decade_1970s',
'loudness decade_1980s','loudness decade_1990s','loudness decade_2000s', 'loudness decade_2010s', 'loudness decade_2020s', 'tempo decade_1920s', 'tempo decade_1930s', 'tempo decade_1940s', 'tempo decade_1950s', 'tempo decade_1960s', 'tempo decade_1990s', 'tempo decade_2000s', 'tempo decade_2010s', 'tempo decade_2020s', 'valence decade_1920s', 'valence decade_1930s', 'valence decade_1940s', 'valence decade_1950s', 'valence decade_2000s', 'valence decade_2010s'. Below is a plot of X being the predicted popularity by the model and Y being the true popularity. 

Interaction Model RMSE score on unseen testing data: 110.30700501688433
Interaction Model R^2 score on unseen testing data: 0.7650354098138841

```{r}

knitr::include_graphics('Interaction Fit.png')


```

Finally, we applied a deep learning approach using the song metrics and temporal information to see how the predictive accuracy would change. 

Neural Networks create an uninterpretable, but perhaps better predictive model for the data. There is a lot of data, such that neural networks may train better in this setting. Furthermore, neural networks can learn complex relationships, interactions, and dependencies between variables, helping reduce the need for manual feature engineering and feature selection.

While LSTMs are often used do the sequential nature of Recurrent Neural Networks and the LSTMs ability to use memory and forget gates to keep and drop important information, the data we have is time series but not sequential, as the observations are generally independent of each other, but rather the observations and their co-variates/popularity scorres are just not independent from time/era. 

Thus, we use an Artificial Neural Network with a ReLU final activation function. In doing so, we bring a longer training and inference time, and the potential of overfitting. Additionally, we do not have the time to truly tune the neural network in terms of its architecture, dropout rate, regularization, optimizer, etc. Meanwhile, a Linear Regression can easily be tuned (for parameters like L1/L2 penalties and such) with a Grid Search in minutes. Finally, with the neural network, we lose interpretability in favor of predictive accuracy.

NN Model RMSE score on unseen testing data: 84.26029562585006
NN Model R^2 score on unseen testing data: 0.8205174201977617

Below is a plot of X being the predicted popularity by the model and Y being the true popularity. 


```{r}

knitr::include_graphics('NN Fit.png')


```

Here, we explore Neural Networks to create an uninterpretable, but perhaps better predictive model for the data. There is a lot of data, such that neural networks may train better in this setting. Furthermore, neural networks can learn complex relationships, interactions, and dependencies between variables, helping reduce the need for manual feature engineering and feature selection.

While LSTMs are often used do the sequential nature of Recurrent Neural Networks and the LSTMs ability to use memory and forget gates to keep and drop important information, the data we have is time series but not sequential, as the observations are generally independent of each other, but rather the observations and their co-variates/popularity scorres are just not independent from time/era. 

Thus, we use an Artificial Neural Network with a ReLU final activation function. In doing so, we bring a longer training and inference time, and the potential of overfitting. Additionally, we do not have the time to truly tune the neural network in terms of its architecture, dropout rate, regularization, optimizer, etc. Meanwhile, a Linear Regression can easily be tuned (for parameters like L1/L2 penalties and such) with a Grid Search in minutes. Finally, with the neural network, we lose interpretability in favor of predictive accuracy.

#### Key Takeaways from Appendix: Modeling

The Neural Network performs better than the Linear Regression, with its R squared of 0.82 and RMSE of 84.2. The RMSE appears to be high in both the linear regression and neural network due to some especially high residuals that come from the recent 2020s data. 


#### Key Takeaways from Appendix: Data Cleaning

In the future, I would filter out extremely recent data as its popularity score is only low due to the recency of it coming out. This data can then be run through the model as a "forecasting set", in which we predict what these songs future popularity scores will be.

Interestingly, even a neural network can not learn the training data that well (> R squared only in the 0.8 range), which I believe a further reflection of the fact that the metrics + temporal information is not a great proxy for predicting popularity.

Some further data cleaning to remove non-songs could also be helpful. For example, there are non-song outliers, songs too recent for a popularity score, and a strong sampling bias in the data in terms of recent songs generally being of a higher popularity than other decades (proportions of popularity scores- some of this is trend in music, but also some less known tracks are just not being included).


#### Key Takeaways from Appendix: Predictive Nature of Data

It is clear from the scatter plots that the data here has high variance- songs with very similar song metrics can and often will have widely different popularities. This is ultimately because the data itself is not nuanced enough to produce a truly great predictor of a song's popularity.

In thinking about what goes into a popular song nowadays, while there are absolutely trends in how songs are made, this will not be able to solely tell you the popularity. There is so much music nowadays that most music with any combination of song metrics will not have a high popularity, since it is challenging to break the glass ceiling. 

Furthermore, more data is definitely required to truly predict a song's popularity score. For example, two artists (e.g. Kendrick Lamar and Billy Joel)releasing songs with the same song metrics will lead to wildly different results. There are many factors that go into songs making the charts nowadays, including how famous an artist already is, its use in social media/pop culture leading to it trending, as well as other factors that make people like a given song. Additionally, data about what niche the artist/its fans fall into could be helpful to know how a song and its given metrics falls into a niche. While this would be helpful, it is still really challenging to create a model that will predict any kind of break through from a small artist, given data on fame. However, one can make a model that ranks songs well in terms of their ability to become popular, given a bunch of small artists, which seems like a great use case of this kind of song data.

Ultimately, music is quite hard to quantify, and more data is required to truly determine what will make people like and listen to songs. 

